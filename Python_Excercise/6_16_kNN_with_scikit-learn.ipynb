{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zH_FN74GbGNI"
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "#  k-Nearest Neighbors with `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3avDRdC6bGNM"
   },
   "source": [
    "<a id=\"learning-objectives\"></a>\n",
    "## Learning Objectives\n",
    "\n",
    "1. Introduce the kNN classification model\n",
    "2. Utilize the kNN model on the iris data set\n",
    "3. Implement scikit-learn's kNN model\n",
    "4. Assess the fit of a kNN Model using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RC3ur13CbGNM"
   },
   "source": [
    "<a id=\"home\"></a>\n",
    "\n",
    "### Lesson Guide\n",
    "- [a) Loading the Iris Data Set](#overview-of-the-iris-dataset)\n",
    "\t- [i) Terminology](#terminology)\n",
    "- [b) Guided Practice: \"Human Learning\" With Iris Data](#exercise-human-learning-with-iris-data)\n",
    "- [c) Human Learning on the Iris Data Set](#human-learning-on-the-iris-dataset)\n",
    "- [d) Guided Intro to KNN: NBA Position KNN Classifier](#knn-classification-nba)\n",
    "\t- [i) Using the Train/Test Split Procedure (K=1)](#using-the-traintest-split-procedure-k)\n",
    "    - [ii) Comparing Testing Accuracy With Null Accuracy (the baseline)](#null-accuracy)\n",
    "- [e) Tuning a KNN Model](#tuning-a-knn-model)\n",
    "\t- [i) What Happens If We View the Accuracy of our Training Data?](#what-happen-if-we-view-the-accuracy-of-our-training-data)\n",
    "\t- [i) Training Error Versus Testing Error](#training-error-versus-testing-error)\n",
    "- [f) Standardizing Features](#standardizing-features)\n",
    "\t- [i) Use `StandardScaler` to Standardize our Data](#use-standardscaler-to-standardize-our-data)\n",
    "- [g) Comparing KNN With Other Models](#comparing-knn-with-other-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOLBLcQYbGNN"
   },
   "source": [
    "In this lesson, we will get an intuitive and practical feel for the **k-Nearest Neighbors** model. kNN is a **non-parametric model**, which means that the model is not represented as an equation with parameters (e.g. the $\\beta$ values in linear regression).\n",
    "\n",
    "First, we will make a model by hand to classify iris flower data. Next, we will automatedly make a model using kNN.\n",
    "\n",
    "> You may have heard of the clustering algorithm **k-Means Clustering**. These techniques have nothing in common, aside from both having a parameter k!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVSp16sBbGNO"
   },
   "source": [
    "<img src=\"assets/iris_overview.png\" style=\"width: 700px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvjgoHZCbGNO"
   },
   "source": [
    "The Iris dataset is a famous machine learning dataset, created in the 1930s by R. Fisher.  It's very complete (and not very big), but is often used for learning about classification models.\n",
    "\n",
    "The dataset comes from UCI (University of California Irvine), which is itself a great source of datasets:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/iris\n",
    "<br />\n",
    "https://archive.ics.uci.edu/ml/index.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhDtWDspbGNP"
   },
   "source": [
    "#### [Home](#home)\n",
    "\n",
    "<a id=\"overview-of-the-iris-dataset\"></a>\n",
    "# <font style = 'color:blue'>a) Loading the Iris Data Set</font>\n",
    "---\n",
    "\n",
    "#### Read the iris data into a pandas DataFrame, including column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3VvKujFebGNQ"
   },
   "outputs": [],
   "source": [
    "# Read the iris data into a DataFrame.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display plots in-notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Increase default figure and font sizes for easier viewing.\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "data = './iris.data'\n",
    "iris = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tizD6wBJbGNR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "iris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "V9H9LNQ6bGNS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
       "5           5.4          3.9           1.7          0.4  Iris-setosa\n",
       "6           4.6          3.4           1.4          0.3  Iris-setosa\n",
       "7           5.0          3.4           1.5          0.2  Iris-setosa\n",
       "8           4.4          2.9           1.4          0.2  Iris-setosa\n",
       "9           4.9          3.1           1.5          0.1  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJL3zBd-bGNS"
   },
   "source": [
    "<a id=\"terminology\"></a>\n",
    "### Terminology\n",
    "\n",
    "- **150 observations** (n=150): Each observation is one iris flower.\n",
    "- **Four features** (p=4): sepal length, sepal width, petal length, and petal width.\n",
    "- **Response**: One of three possible iris species (setosa, versicolor, or virginica)\n",
    "- **Classification problem** because response is categorical (i.e. a discrete value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "GW1Pr3agbGNS"
   },
   "source": [
    "#### [Home](#home)\n",
    "\n",
    "<a id=\"exercise-human-learning-with-iris-data\"></a>\n",
    "# <font style = 'color:blue'>b) Guided Practice: \"Human Learning\" With Iris Data</font>\n",
    "\n",
    "**Question:** Can we predict the species of an iris using petal and sepal measurements? Together, we will:\n",
    "\n",
    "1. Read the iris data into a pandas DataFrame, including column names.\n",
    "2. Gather some basic information about the data.\n",
    "3. Use sorting, split-apply-combine, and visualization to look for differences between species.\n",
    "4. Write down a set of rules that could be used to predict species based on iris measurements.\n",
    "\n",
    "**BONUS:** Define a function that accepts a row of data and returns a predicted species. Then, use that function to make predictions for all existing rows of data and check the accuracy of your predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "GSVJqFDTbGNT"
   },
   "source": [
    "#### Gather some basic information about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5c84NeAGbGNT"
   },
   "outputs": [],
   "source": [
    "# 150 observations, 5 columns (the 4 features & response)\n",
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9ivG9gfbGNT"
   },
   "outputs": [],
   "source": [
    "iris.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HOhwr912bGNU"
   },
   "outputs": [],
   "source": [
    "# Verify the basic stats look appropriate\n",
    "iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tayEtWjsbGNU"
   },
   "outputs": [],
   "source": [
    "# Test for imbalanced classes\n",
    "iris.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNQ9Y3yWbGNU"
   },
   "outputs": [],
   "source": [
    "# Verify we are not missing any data\n",
    "iris.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "nHXUtk6pbGNU"
   },
   "source": [
    "#### Use sorting, split-apply-combine, and/or visualization to look for differences between species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQvx7JBdbGNU"
   },
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BqZdn8RVbGNV"
   },
   "outputs": [],
   "source": [
    "# Sort the DataFrame by petal_width.\n",
    "iris.sort_values(by='petal_width', ascending=True, inplace=True)\n",
    "iris.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCe318XlbGNV"
   },
   "outputs": [],
   "source": [
    "# Sort the DataFrame by petal_width and display the NumPy array.\n",
    "iris.sort_values(by='petal_width', ascending=True).values[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "jE_KChhLbGNV"
   },
   "source": [
    "#### Split-apply-combine: Explore the data while using a `groupby` on `'species'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "or_v3gHtbGNV"
   },
   "outputs": [],
   "source": [
    "# Mean of sepal_length, grouped by species.\n",
    "iris.groupby(by='species', axis=0).sepal_length.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZ809gdUbGNV"
   },
   "outputs": [],
   "source": [
    "# Mean of all numeric columns, grouped by species.\n",
    "iris.groupby('species').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9IBzHiRbGNW"
   },
   "outputs": [],
   "source": [
    "# describe() of all numeric columns, grouped by species.\n",
    "iris.groupby('species').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1WGsfePbGNW"
   },
   "outputs": [],
   "source": [
    "# Box plot of petal_width, grouped by species.\n",
    "iris.boxplot(column='petal_width', by='species', figsize=(8,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aYV-cp0bGNW"
   },
   "outputs": [],
   "source": [
    "# Box plot of all numeric columns, grouped by species.\n",
    "iris.boxplot(by='species', rot=45, figsize=(8,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dTh7hmIubGNW"
   },
   "outputs": [],
   "source": [
    "# Map species to a numeric value so that plots can be colored by species.\n",
    "iris['species_num'] = iris.species.map({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2})\n",
    "\n",
    "# Alternative method:\n",
    "iris['species_num'] = iris.species.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U384jvHebGNW"
   },
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w8ze62ELbGNX"
   },
   "outputs": [],
   "source": [
    "# Scatterplot of petal_length vs. petal_width, colored by species\n",
    "iris.plot(kind='scatter', x='petal_length', y='petal_width', c='species_num', colormap='brg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjHs3z2LbGNX"
   },
   "outputs": [],
   "source": [
    "# Scatter matrix of all features, colored by species.\n",
    "pd.plotting.scatter_matrix(iris.drop('species_num', axis=1), c=iris.species_num, figsize=(12, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "d3g6elwRbGNX"
   },
   "source": [
    "#### <font style='color:green'>Exercise: Using the graphs and data above, can you write down a set of rules that can accurately predict species based on iris measurements?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNI21fa1bGNX"
   },
   "outputs": [],
   "source": [
    "# Feel free to do more analysis if needed to make good rules!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "z8Dk_PtWbGNX"
   },
   "source": [
    "#### Bonus: If you have time during the class break or after class, try to implement these rules to make your own classifier!\n",
    "\n",
    "Write a function that accepts a row of data and returns a predicted species. Then, use that function to make predictions for all existing rows of data and check the accuracy of your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sj4Y2VekbGNY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8opRE4d1bGNY"
   },
   "source": [
    "#### [Home](#home)\n",
    "\n",
    "<a id=\"human-learning-on-the-iris-dataset\"></a>\n",
    "# <font style = 'color:blue'>c) Human Learning on the Iris Data Set</font>\n",
    "---\n",
    "\n",
    "How did we (as humans) predict the species of an iris?\n",
    "\n",
    "1. We observed that the different species had (somewhat) dissimilar measurements.\n",
    "2. We focused on features that seemed to correlate with the response.\n",
    "3. We created a set of rules (using those features) to predict the species of an unknown iris.\n",
    "\n",
    "We assumed that if an **unknown iris** had measurements similar to **previous irises**, then its species was most likely the same as those previous irises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r04JkFXNbGNY"
   },
   "outputs": [],
   "source": [
    "# Allow plots to appear in the notebook.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Increase default figure and font sizes for easier viewing.\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# Create a custom color map.\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDmuNr_obGNY"
   },
   "outputs": [],
   "source": [
    "# Map each iris species to a number.\n",
    "iris['species_num'] = iris.species.map({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKPA0lVNbGNY"
   },
   "outputs": [],
   "source": [
    "# Box plot of all numeric columns, grouped by species.\n",
    "iris.drop('species_num', axis=1).boxplot(by='species', rot=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjBAQ0N5bGNY"
   },
   "outputs": [],
   "source": [
    "# Create a scatterplot of PETAL LENGTH versus PETAL WIDTH and color by SPECIES.\n",
    "iris.plot(kind='scatter', x='petal_length', y='petal_width', c='species_num', colormap=cmap_bold);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ldv3J9VsbGNY",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This conversion relies on a 'prediction' column, which is created in the Bonus section of the Exercise in b) above.  Look at the Solution file if needed to get this code.\n",
    "iris['pred_num'] = iris.prediction.map({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2})\n",
    "\n",
    "# Create a scatter plot of PETAL LENGTH versus PETAL WIDTH and color by PREDICTION.\n",
    "iris.plot(kind='scatter', x='petal_length', y='petal_width', c='pred_num', colormap=cmap_bold);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLBS7-V6bGNY"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeG8C9Q5bGNZ"
   },
   "source": [
    "#### [Home](#home)\n",
    "\n",
    "<a id=\"knn-classification-nba\"></a>\n",
    "# <font style = 'color:blue'>d) Guided Intro to KNN: NBA Position KNN Classifier</font>\n",
    "\n",
    "For the rest of the lesson, we will be using a dataset containing the 2015 season statistics for ~500 NBA players. This dataset leads to a nice choice of K, as we'll see below. The columns we'll use for features and the target we are tryng to predict - a player's position ('pos') are:\n",
    "\n",
    "\n",
    "| Column | Meaning |\n",
    "| ---    | ---     |\n",
    "| pos | C: Center. F: Front. G: Guard |\n",
    "| ast | Assists per game | \n",
    "| stl | Steals per game | \n",
    "| blk | Blocks per game |\n",
    "| tov | Turnovers per game | \n",
    "| pf  | Personal fouls per game | \n",
    "\n",
    "For information about the other columns, see [this glossary](https://www.basketball-reference.com/about/glossary.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TiOrBLKMbGNZ"
   },
   "outputs": [],
   "source": [
    "# Read the NBA data into a DataFrame.\n",
    "import pandas as pd\n",
    "\n",
    "path = 'data/NBA_players_2015.csv'\n",
    "nba = pd.read_csv(path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LOWXzFIbGNZ"
   },
   "outputs": [],
   "source": [
    "nba.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9yxFToO1bGNZ"
   },
   "outputs": [],
   "source": [
    "nba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eaXFU6wubGNZ"
   },
   "outputs": [],
   "source": [
    "# Map positions to numbers\n",
    "nba['pos_num'] = nba.pos.map({'C':0, 'F':1, 'G':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCXzFQDpbGNZ"
   },
   "outputs": [],
   "source": [
    "# Create feature matrix (X).\n",
    "feature_cols = ['ast', 'stl', 'blk', 'tov', 'pf']\n",
    "X = nba[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRfXRsRtbGNZ"
   },
   "outputs": [],
   "source": [
    "# Create response vector (y).\n",
    "y = nba.pos_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "EV5hYDCebGNZ"
   },
   "source": [
    "<a id=\"using-the-traintest-split-procedure-k\"></a>\n",
    "### Using the Train/Test Split Procedure (k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpG2xqXCbGNa"
   },
   "source": [
    "#### Step 1: Import the model class we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEzwfhxIbGNa"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idmj_ytXbGNa"
   },
   "source": [
    "#### Step 2: Split X and y into training and testing sets (using `random_state` for reproducibility)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyKZf8jlbGNa"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GdAgDz3bGNa"
   },
   "source": [
    "#### Step 3: Train the model on the training set (using k=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8qy65lCbGNa"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILl1Qb_FbGNa"
   },
   "source": [
    "#### Step 4: Test the model on the testing set and check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlbJrBrGbGNa"
   },
   "outputs": [],
   "source": [
    "y_pred_class = knn.predict(X_test)\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cz0lpyJtbGNa"
   },
   "source": [
    "<font style='color:green'>**Question:** If we had trained on the entire dataset and tested on the entire dataset, using 1-KNN what accuracy would we get? Why?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "p_PgCnUrbGNb"
   },
   "source": [
    "#### Repeating for k=50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_jVHKN-bGNb"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=50)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrSq86OQbGNb"
   },
   "source": [
    "<font style='color:green'>**Question:** Suppose we again train and test on the *entire* data set (not splitting it as above), but using 50-KNN. Would we expect the accuracy to be the same as compared to 1-KNN?  Why?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "cH709lyzbGNb"
   },
   "source": [
    "<a id=\"null-accuracy\"></a>\n",
    "### ii) Comparing Testing Accuracy With Null Accuracy (the baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "r8NJ3DghbGNb"
   },
   "source": [
    "In classification tasks, Null Accuracy is the accuracy that can be achieved by **always predicting the most frequent class**. For example, if most players are Centers, we would always predict Center.\n",
    "\n",
    "The null accuracy is a benchmark against which you may want to measure every classification model. It is our baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mk4jenebGNb"
   },
   "source": [
    "#### Examine the class distribution from the training set.\n",
    "\n",
    "Remember that we are comparing KNN to this simpler model. So, we must find the most frequent class **of the training set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udIRNbnBbGNb"
   },
   "outputs": [],
   "source": [
    "most_freq_class = y_train.value_counts().index[0]\n",
    "\n",
    "print(y_train.value_counts())\n",
    "most_freq_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQ6142yvbGNb"
   },
   "source": [
    "#### Compute the null accuracy / baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tiLngqT9bGNb"
   },
   "outputs": [],
   "source": [
    "y_test.value_counts()[most_freq_class] / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9SLc3DZbGNc"
   },
   "source": [
    "#### [Home](#home)\n",
    "\n",
    "<a id=\"tuning-a-knn-model\"></a>\n",
    "# <font style = 'color:blue'>e) Tuning a KNN Model</font>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RFTOB3HbGNc"
   },
   "outputs": [],
   "source": [
    "# Instantiate the model (using the value K=5).\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the model with data.\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Store the predicted response values.\n",
    "y_pred_class = knn.predict(X)\n",
    "\n",
    "print((metrics.accuracy_score(y, y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HeoXI0HbGNc"
   },
   "outputs": [],
   "source": [
    "# Calculate predicted probabilities of class membership.\n",
    "# Each row sums to one and contains the probabilities of the point being a 0-Center, 1-Front, 2-Guard.\n",
    "knn.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xC_Y_8gRbGNc"
   },
   "source": [
    "In the next class, we'll discuss **model evaluation procedures**, which allow us to use our existing labeled data to estimate how well our models are likely to perform on out-of-sample data (spoiler alert: we'll be revisiting Type I and Type II errors). These procedures will help us to tune our models and choose between different types of models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhxpOAsJbGNc"
   },
   "source": [
    "<a id=\"what-happen-if-we-view-the-accuracy-of-our-training-data\"></a>\n",
    "### What Happens If We View the Accuracy of our Training Data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxWK8c5RbGNc"
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in range(1,100):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred = knn.predict(X)\n",
    "    score = float(sum(pred == y)) / len(y)\n",
    "    scores.append([k, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_374D6CmbGNc"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(scores,columns=['k','score'])\n",
    "data.plot.line(x='k',y='score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnbu3oiTbGNc"
   },
   "source": [
    "<font style='color:green'>**Question:** As K increases, why does the accuracy fall?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "wj5D1AznbGNc"
   },
   "source": [
    "#### Search for the 'best' value of K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dctbj_IvbGNc"
   },
   "outputs": [],
   "source": [
    "# Calculate TRAINING ERROR and TESTING ERROR for K=1 through 100.\n",
    "\n",
    "k_range = list(range(1, 101))\n",
    "training_error = []\n",
    "testing_error = []\n",
    "\n",
    "# Find test accuracy for all values of K between 1 and 100 (inclusive).\n",
    "for k in k_range:\n",
    "\n",
    "    # Instantiate the model with the current K value.\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate training error (error = 1 - accuracy).\n",
    "    y_pred_class = knn.predict(X)\n",
    "    training_accuracy = metrics.accuracy_score(y, y_pred_class)\n",
    "    training_error.append(1 - training_accuracy)\n",
    "    \n",
    "    # Calculate testing error.\n",
    "    y_pred_class = knn.predict(X_test)\n",
    "    testing_accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "    testing_error.append(1 - testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qx7RBnfbGNd"
   },
   "outputs": [],
   "source": [
    "# Allow plots to appear in the notebook.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nx15zb8gbGNd"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame of K, training error, and testing error.\n",
    "column_dict = {'K': k_range, 'training error':training_error, 'testing error':testing_error}\n",
    "df = pd.DataFrame(column_dict).set_index('K').sort_index(ascending=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYzN9vvNbGNd"
   },
   "outputs": [],
   "source": [
    "# Plot the relationship between K (HIGH TO LOW) and TESTING ERROR.\n",
    "df.plot(y='testing error');\n",
    "plt.xlabel('Value of K for KNN');\n",
    "plt.ylabel('Error (lower is better)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NeH5cyNhbGNd"
   },
   "outputs": [],
   "source": [
    "# Find the minimum testing error and the associated K value.\n",
    "df.sort_values('testing error').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaVdIcXZbGNd"
   },
   "outputs": [],
   "source": [
    "# Alternative method:\n",
    "min(list(zip(testing_error, k_range)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKW2OShBbGNd"
   },
   "source": [
    "<a id=\"training-error-versus-testing-error\"></a>\n",
    "### Training Error Versus Testing Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLjNry9zbGNd"
   },
   "outputs": [],
   "source": [
    "# Plot the relationship between K (HIGH TO LOW) and both TRAINING ERROR and TESTING ERROR.\n",
    "df.plot();\n",
    "plt.xlabel('Value of K for KNN');\n",
    "plt.ylabel('Error (lower is better)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEF3Tp5fbGNd"
   },
   "source": [
    "- **Training error** decreases as model complexity increases (the lower the value of K, the higher the complexity).\n",
    "- **Testing error** is minimized at the optimum model complexity.\n",
    "\n",
    "Evaluating the training and testing error is important. For example:\n",
    "\n",
    "- If the training error is much lower than the test error, then our model is likely overfitting. \n",
    "- If the test error starts increasing as we vary a hyperparameter, we may be overfitting.\n",
    "- If either error plateaus, our model is likely underfitting (not complex enough)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "NSihdvrHbGNd"
   },
   "source": [
    "#### Making Predictions on Out-of-Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "ctddbBs5bGNe"
   },
   "source": [
    "Given the statistics of a (truly) unknown NBA player, how do we predict his position?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkzVIWMTbGNe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Instantiate the model with the best-known parameters.\n",
    "knn = KNeighborsClassifier(n_neighbors=14)\n",
    "\n",
    "# Re-train the model with X and y (not X_train and y_train). Why?\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Make a prediction for an out-of-sample observation.\n",
    "knn.predict(np.array([2, 1, 0, 1, 2]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "MDIP2mA9bGNe"
   },
   "source": [
    "What could we conclude?\n",
    "\n",
    "- When using KNN on this data set with these features, the **best value for K** is likely to be around 14.\n",
    "- Given the statistics of an **unknown player**, we estimate that we would be able to correctly predict his position about 74% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aM5plNfFbGNe"
   },
   "source": [
    "#### [Home](#home)\n",
    "\n",
    "<a id=\"standardizing-features\"></a>\n",
    "# <font style = 'color:blue'>f) Standardizing Features</font>\n",
    "---\n",
    "\n",
    "There is one major issue that applies to many machine learning models: they are sensitive to the scales of features (feature scale). \n",
    "\n",
    "> KNN in particular is sensitive to feature scale because it (by default) uses the Euclidean distance metric. To determine closeness, Euclidean distance sums the square difference along each axis. So, if one axis has large differences and another has small differences, the former axis will contribute much more to the distance than the latter axis.\n",
    "\n",
    "This means that it matters whether our feature are centered around zero and have similar variance to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfAmGteXbGNe"
   },
   "source": [
    "Unfortunately, most data does not naturally start at a mean of zero and a shared variance. Other models tend to struggle with scale as well, even linear regression, when you get into more advanced methods such as regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXSQdJUnbGNe"
   },
   "source": [
    "Fortunately, this is an easy fix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGfrDuhybGNe"
   },
   "source": [
    "<a id=\"use-standardscaler-to-standardize-our-data\"></a>\n",
    "### Use `StandardScaler` to Standardize our Data\n",
    "\n",
    "StandardScaler standardizes our data by subtracting the mean from each feature and dividing by its standard deviation.  It can be used with Linear Regression as well as Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3gftRfjbGNe"
   },
   "source": [
    "#### Separate feature matrix and response for scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PSHrnpT6bGNf"
   },
   "outputs": [],
   "source": [
    "# Create feature matrix (X).\n",
    "feature_cols = ['ast', 'stl', 'blk', 'tov', 'pf']\n",
    "\n",
    "X = nba[feature_cols]\n",
    "y = nba.pos_num  # Create response vector (y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHZ4zfD2bGNf"
   },
   "source": [
    "#### Create the train/test split.\n",
    "\n",
    "Notice that we create the train/test split first. This is because we will reveal information about our testing data if we standardize right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGvm-vTKbGNf"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "S2w6hPkVbGNf"
   },
   "source": [
    "#### Instantiate and fit `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xm6Z8ozwbGNf"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3rn_yTVbGNf"
   },
   "source": [
    "#### Fit a KNN model and look at the testing error.\n",
    "Can you find a number of neighbors that improves our results from before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Hop307WbGNf"
   },
   "outputs": [],
   "source": [
    "# Calculate testing error.\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class = knn.predict(X_test)\n",
    "testing_accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "testing_error = 1 - testing_accuracy\n",
    "\n",
    "print(testing_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dE6T_3KWbGNf"
   },
   "source": [
    "#### [Home](#home)\n",
    "\n",
    "<a id=\"comparing-knn-with-other-models\"></a>\n",
    "# <font style = 'color:blue'>g) Comparing KNN With Other Models</font>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45jIxkzwbGNf"
   },
   "source": [
    "**Advantages of KNN:**\n",
    "\n",
    "- It's **simple to understand** and explain.\n",
    "- **Model training is fast**.\n",
    "- It can be used for classification and regression (for regression, take the average value of the K nearest points!).\n",
    "- **Being a non-parametric method, it is often successful in classification situations where the decision boundary is very irregular.**\n",
    "\n",
    "**Disadvantages of KNN:**\n",
    "\n",
    "- It **must store all of the training data**.\n",
    "- Its **prediction phase can be slow when n is large**.\n",
    "- It is sensitive to irrelevant features.\n",
    "- It is **sensitive to the scale of the data**.\n",
    "- Accuracy is (generally) not competitive with the best supervised learning methods."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "oeG8C9Q5bGNZ",
    "UpG2xqXCbGNa",
    "idmj_ytXbGNa",
    "3GdAgDz3bGNa",
    "ILl1Qb_FbGNa",
    "p_PgCnUrbGNb",
    "M9SLc3DZbGNc",
    "wj5D1AznbGNc",
    "NSihdvrHbGNd",
    "aM5plNfFbGNe",
    "l3gftRfjbGNe",
    "QHZ4zfD2bGNf",
    "S2w6hPkVbGNf",
    "k3rn_yTVbGNf",
    "dE6T_3KWbGNf"
   ],
   "name": "6_16_kNN_with_scikit-learn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
